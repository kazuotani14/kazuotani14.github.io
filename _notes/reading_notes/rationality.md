# Rationality 

### References 

* Rationality: From AI to Zombies, by Eliezer Yudkowsky

##### Questions

* How do we commit to making the optimal decision (in terms of expected values)?
* How should we approach life? 

##### Fields/topics covered

* Evolutionary psychology
* Probability theory (Bayesian)
* Decision theory
* Quantum physics

### Notes

* Rationality: systematically improving the accuracy of your beliefs (epistemic) and systematically achieving your values (instrumental)
    * “when a mental pattern serves you well, we call that rationality” 
    * Note that there's a big difference vs "rationalization"

* Beliefs only matter in the way they affect your predictions of the future, and your actions based on those predictions. If a belief doesn’t change any of these things, it’s irrelevant. (Is this a consequentialist view?)
    * Beliefs are only helpful in their predictive ability 
    * "Rationalist virtue of empiricism consists of constantly asking which experiences our beliefs predict - or better yet, prohibit"
    * "don’t ask what to believe—ask what to anticipate"

* "That which can be destroyed by the truth should be."

* "Pretending to be wise" - refusing to look at evidence in order to stay neutral in a time of conflict
    * "“Washing one’s hands of the conflict between the powerful and the powerless means to side with the powerful, not to be neutral.”1 A playground is a great place to be a bully, and a terrible place to be a victim, if the teachers don’t care who started it. And likewise in international politics: A world where the Great Powers refuse to take sides and only demand immediate truces is a great world for aggressors and a terrible place for the aggressed. But, of course, it is a very convenient world in which to be a Great Power or a school principal."
    * "neutrality is a definite judgment. It is not staying above anything. It is putting forth the definite and particular position that the balance of evidence in a particular case licenses only one summation, which happens to be neutral."
    * Often, a person's authority seems to depend on staying neutral. But this is wrong

* Leave a line of retreat for your enemies:  The hope is that it takes less courage to visualize an uncomfortable state of affairs as a thought experiment, than to consider how likely it is to be true. But then after you do the former, it becomes easier to do the latter. Also applies to your own beliefs. I still plan my retreats, not because I’m planning to retreat, but because planning my retreat in advance helps me think about the problem without attachment.

* Science is made up of generalizations which apply to many particular instances, so that you can run new real-world experiments which test the generalization, and thereby verify for yourself that the generalization is true, without having to trust anyone’s authority. Science is the publicly reproducible knowledge of humankind.
    *  The special standards we impose upon science are pragmatic choices. Nowhere upon the stars or the mountains is it written that p < 0.05 shall be the standard for scientific publication. Many now argue that 0.05 is too weak, and that it would be useful to lower it to 0.01 or 0.001
    * Perhaps future generations, acting on the theory that science is the public, reproducible knowledge of humankind, will only label as “scientific” papers published in an open-access journal. If you charge for access to the knowledge, is it part of the knowledge of humankind? Can we trust a result if people must pay to criticize it? Is it really science? The question “Is it really science?” is ill-formed. Is a $20,000/year closed- access journal really Bayesian evidence? As with the police commissioner’s private assurance that Wulky is the kingpin, I think we must answer “Yes.” But should the closed-access journal be further canonized as “science”? Should we allow it into the special, protected belief pool? For myself, I think science would be better served by the dictum that only open knowledge counts as the public, reproducible knowledge pool of humankind.

* Just because "scientists" know something, or have solved a problem, doesn't mean that it's any less important for you to try it and understand it. Be curious!
    * "Because science" shouldn't be a curiosity stopper. Neither should "passwords" like "because electricity". This doesn't give you knowledge with power of predictions
    * Other buzz words that hide lack of understanding: "complexity", "emergence"

* If you are told that a deck of cards contains 70% blue cards and 30% red cards, and you want to guess the color of the next flipped card, the optimal strategy is to guess blue every time. However, participants often do a random mix of blue/red predictions, with slightly more blues. 
    * It is a counterintuitive idea that the optimal strategy can be to think lawfully, even under conditions of uncertainty.

* Probability to odd ratio: $O = P/(1−P)$. e.g. $P=0.25 \rightarrow O=1:3$. Isomorphic mapping
    * More convenient for Bayesian updates - simple multiplications. A representation that makes it even simpler to do Bayesian updates is the log odds—this is how E. T. Jaynes recommended thinking about probabilities. This allows additions for updates
    * 0 and 1 are not probabilities! Nothing has infinite certainty

*  Correspondence bias: the tendency to draw inferences about a person’s unique and enduring dispositions from behaviors that can be entirely explained by the situations in which they occur. To understand why people act the way they do, we must first realize that everyone sees themselves as behaving normally. Ask what situations people see themselves as being in
* Planning bias

* Knowing too much about biases can hurt you, because you can use this knowledge as ammunition to argue against things that you don't like, while being unaware of other biases that you are falling into

* Motivated Stopping and Motivated Continuation: In real life you have to gather evidence, which may be costly, and at some point decide that you have enough evidence to stop and choose. Sequential data collection. When we have a hidden motive for choosing the “best” current option, we have a hidden motive to stop, and choose, and reject consideration of any more options. When we have a hidden motive to reject the current best option, we have a hidden motive to suspend judgment pending additional evidence, to generate more options. 
    * The decision to terminate a search procedure (temporarily or permanently) is, like the search procedure itself, subject to bias and hidden motives. 
    * You should suspect motivated stopping when you close off search, a er coming to a comfortable conclusion, and yet there’s a lot of fast cheap evidence you haven’t gathered yet—there are websites you could visit, there are counter-counter arguments you could consider, or you haven’t closed your eyes for  ve minutes by the clock trying to think of a better option. You should suspect motivated continuation when some evidence is leaning in a way you don’t like, but you decide that more evidence is needed—expensive evidence that you know you can’t gather anytime soon, as opposed to something you’re going to look up on Google in thirty minutes—before you’ll have to do anything uncomfortable.

* “Is this my true rejection?” What your failed prospects tell you is the reason for rejection, may not make the real difference; and you should ponder that carefully before spending huge efforts. If the venture capitalist says “If only your sales were growing a little faster!,” or if the potential customer says “It seems good, but you don’t have feature X,” that may not be the true rejection. Fixing it may, or may not, change anything. 

* Inferential distances: consider how many steps people will have to take when explaining concepts

* Priming and contamination: concepts activate related concepts in our brains, can affect judgments. Used for "anchoring"

* Two rational people, given the same evidence, can't "agree to disagree" http://www.overcomingbias.com/2006/12/agreeing_to_agr.html

* Spinoza suggested that we first passively accept a proposition in the course of comprehending it, and only afterward actively disbelieve propositions which are rejected by consideration. Experiments show that this is actually how we think.

* Concept of cached beliefs/thoughts: humans can’t think that fast (100Hz tops, but very parallel). To work with this, we have precomputed responses to certain questions/statements. We often bring them up without thinking about them once they are set in stone. To be truly rational, we need to reconsider them from the ground up and make an effort to not rely on cached beliefs 
    * What patterns are being completed, inside your mind, that you never chose to be there?
    * Replace the symbol with the substance: try to see things as they really are, not as the labels cached in your head. 
    * To categorize is to throw away information. e.g. If a coin lands “heads,” you don’t know its radial orientation. You want to use categories to throw away irrelevant information, to sift  gold from dust, but often the standard categorization ends up throwing out relevant information too
    * we want "original seeing"

* 9/11: 
    *  Prediction: "The overreaction to this will be ten times worse than the original event."
    * no one would dare to be the voice of restraint, of proportionate response. Any politician who’d said “6,000 deaths is 1/8 the annual US casualties from automobile accidents,” would have been asked to resign the same hour.
    * If the USA had completely ignored the 9/11 attack—just shrugged and re- built the building—it would have been better than the real course of history. But that wasn’t a political option. Even if anyone privately guessed that the immune response would be more damaging than the disease, American politicians had no career-preserving choice but to walk straight into al-Qaeda’s trap.

* Asch's conformity experiments and implications
    * An individual, working alone, will have natural doubts.  ey will think to themselves “Can I really do XYZ?,” because there’s nothing impolite about doubting your own competence. But when two uncon dent people form a group, it is polite to say nice and reassuring things, and impolite to question the other person’s competence. Together they become more optimistic than either would be on their own, each one’s doubts quelled by the other’s seemingly con dent reassurance, not realizing that the other person initially had the same inner doubts.
    * Asch’s experiment shows that the power of dissent to inspire others is real. Asch’s experiment shows that the power of conformity is real. If everyone refrains from voicing their private doubts, that will indeed lead groups into madness. But history abounds with lessons on the price of being the first, or even the second, to say that the Emperor has no clothe

* Evolution is really stupid and slow. How long would it take for a beneficial mutation that conveys a fitness advantage to spread through the whole population? $\text{Generations to fixation = } 2 ln(N)/s$, where $N$ is the population size and $s$ is the percentage advantage in fitness. 

* Species, groups, individuals aren't optimized through evolution; genes are! “Replication of the fitter”
    *  The real struggle in natural selection is not the competition of organisms for resources; this is an ephemeral thing when all the participants will vanish in another generation.  The real struggle is the competition of alleles for frequency in the gene pool.

* “If a tree falls in the forest and noone hears it, does it make a sound?” Standard analysis for this question is that the disagreement is over the definition of “sound”: “acoustic vibrations” vs “sensation of hearing/auditory processing in a brain” people often mistake words for meaning; words just mean whatever people agree they mean. To get around this, “dereference the pointer” of the word by actually simulating the mental model 

* Before you can question your intuitions, you have to realize that what your mind’s eye is looking at is an intuition—some cognitive algorithm, as seen from the inside—rather than a direct perception of the Way things Really Are. People cling to their intuitions, I think, not so much because they believe their cognitive algorithms are perfectly reliable, but because they can’t see their intuitions as the way their cognitive algorithms happen to look from the inside.

* Naive Bayes: assume conditional independence among factors

* When you open a refrigerator and find that the orange juice is gone, you think “Darn, I’m out of orange juice.”  e sound of these words is probably represented in your auditory cortex, as though you’d heard someone else say it. (Why do I think this? Because native Chinese speakers can remember longer digit sequences than English-speakers. Chinese digits are all single syllables, and so Chinese speakers can remember around ten digits, versus the famous “seven plus or minus two” for English speakers.  ere appears to be a loop of repeating sounds back to yourself, a size limit on working memory in the auditory cortex, which is genuinely phoneme-based.)

* Probability is a property of the observer, not an inherent property of the object. 
    * Besides, as a Bayesian, I don’t believe in phenomena that are inherently confusing. Confusion exists in our models of the world, not in the world itself.

* The map is not the territory. High-level maps are in our minds
    * Where you see a single confusing thing, with protean and self-contradictory attributes, it is a good guess that your map is cramming too much into one point—you need to pry it apart and allocate some new buckets.
    * In the real world, there are only lowest-level laws governing the real world (reductionism, “the plane doesn’t exist, only the atoms/quarks do) 

* Artificial Intelligence is fundamentally about reducing the mental to the non-mental.

* Curiosity seeks to annihilate itself; there is no curiosity that does not want an answer. The glory of glorious mystery is to be solved, after which it ceases to be mystery. Be wary of those who speak of being open-minded and modestly confess their ignorance.  ere is a time to confess your ignorance and a time to relinquish your ignorance.

* Antoine de Saint-Exupéy  said: “Perfection is achieved not when there is nothing less  to add, but when there is nothing less to take away.”3 Simplicity is virtuous in belief, design, planning, and justification. When you profess a huge belief with many details, each additional detail is another chance for the belief to be wrong. Each specification adds to your burden; if you can lighten your burden you must do so.

* In every art, if you do not seek perfection you will halt before taking your first steps. If perfection is impossible that is no excuse for not trying. Hold yourself to the highest standard you can imagine, and look for one still higher. Do not be content with the answer that is almost right; seek one that is exactly right.

* These then are twelve virtues of rationality: Curiosity, relinquishment, lightness, evenness, argument, empiricism, simplicity, humility, perfectionism, precision, scholarship, and the void.

* To do things that are very difficult or “impossible,” First you have to not run away.  That takes seconds. Then you have to work. That takes hours. Then you have to stick at it. That takes years.

* Money as the universal unit of caring about something. Money was invented so that people could specialize at one thing and rely on others to do what they're good at, in order to have our needs met. Very often, we can make more of an impact by paying someone to work on their specialty, instead of trying to do it ourselves. This has implications on altruistic efforts: e.g. a lawyer might want to feed the poor. Instead of working at a soup kitchen for a few hours, he can do more good by working a few hours extra as a lawyer and paying someone else to work at the soup kitchen full-time. This is probably true for most corporate "community involvement" projects... They would be able to do more good by just donating some percentage of their income to a verifiably effective charity, instead of donating their time. One good thing that comes out of donating time is "warm fuzzy" feelings, from direct contact with benificiaries. If this warm fuzzy feeling helps the lawyer reaffirm his decision to donate money to the organization, this is good. 

* Beware of other-optimizing: try not to push "tips" for productivity, diet, etc. on to people, especially if you are in a position of potential power/influence. What works for you may not work for others, since the "tip" is most likely not a general rule

* The opposite of stupidity is not intelligence: if you take everything that a stupid person says and do the opposite, that doesn't make you a genius

* science itself is a special case of Bayes’s theorem; experimental evidence is Bayesian evidence
    * And that’s Bayes’s theorem. Rational inference on the left  end, physical causality on the right end; an equation with mind on one side and reality on the other. Remember how the scientific method turned out to be a special case of Bayes’s theorem? If you wanted to put it poetically, you could say that Bayes’s theorem binds reasoning into the physical universe.

* Occam's razor: principle of parsimony
    * “Occam means counting laws, not counting objects.”
    * e.g. Robert Heinlein once claimed (tongue-in-cheek, I hope) that the “simplest explanation” is always: “ the woman down the street is a witch; she did it.”. The word "witch" has a lot of complexity hidden in it. 
    * Evaluate theories with: Kolmogorov complexity and Solomonoff induction, or Minimum Message Length
        * How big would a computer program have to be to embody this hypothesis? 
    * It takes more Bayesian evidence—more successful pre- dictions, or more precise predictions—to justify more complex hypotheses, because the prior probability on any hypotheses (in the Solomonoff induction view) is $2^{-L(P)}$, where $L(P)$ is the length of program $P$ in bits

* Conjunction rule of probability theory: $P(X,Y) \leq P(X)$
    * the conjunction rule does give us a rule of monotonic decrease in probability: as you tack more details onto a story, and each additional detail can potentially be true or false, the story’s probability goes down monotonically

* Probability theory should be at the root of rational decision-making: calculate expected rewards. "Shut up and multiply"

What I got out of the quantum physics section:

* The world can be defined in terms of configurations (joint configurations of particles)
* Decoherence ("many worlds" theory) makes more sense than the "single-world" theory that requires quantum superposition to "collapse" into a single state, with probability of all other states going to zero, at some specific point in time. The single-world hypothesis adds a new rule that goes against much of what we know, and thus is significantly more complex
* Macroscopic decoherence, a.k.a. many-worlds, was first proposed in a 1957 paper by Hugh Everett III. The paper was ignored. John Wheeler told Everett to see Niels Bohr. Bohr didn’t take him seriously. Crushed, Everett left academic physics, invented the general use of Lagrange multipliers in optimization problems, and became a multimillionaire.
    * LOL

### Other material

Why to have kids (naval): 

* It makes you love something more than you love yourself
* Your ancestors fought so hard to pass on their DNA, which you are a continuation of. Are you really gonna be the one to break it? 

Not from the book but relevant: 
“Emotions is the net present value of the future impact of the present moment as calculated by your genes.” -Naval Ravikant
Emotions are your primitive value function! Understand this and take it into account, but don’t completely disregard your emotions 

https://medium.com/incerto/how-to-be-rational-about-rationality-432e96dd4d1a
Nassim Taleb argues that we can’t argue about “rational beliefs”, only “rational actions”, with “rational” defined as whatever encourages survival at an individual, collective, tribal or general level. 
* How much you truly “believe” in something can only be manifested through what you are willing to risk for it.
* When you consider beliefs do not assess them in how they compete with other beliefs, but consider the survival of the populations that have them.
* Rationality is not what has conscious verbalistic explanatory factors; it is only what aids survival, avoids ruin.